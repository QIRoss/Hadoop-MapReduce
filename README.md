# Hadoop MapReduce Spark

Studies based in day 71-72 and 79-80 of 100 Days System Design for DevOps and Cloud Engineers.

https://deoshankar.medium.com/100-days-system-design-for-devops-and-cloud-engineers-18af7a80bc6f

Days 71–80: High-Performance Computing (HPC) and Data Processing

Day 71–72: Set up a Hadoop cluster and perform data processing with Hadoop MapReduce.

Day 79–80: Optimize a Spark cluster for large-scale data processing.

## Project Overview

This study follow some tutorials to learn more about Hadoop ecosystem.

I'll link the tutorials here as submodules so you can follow them too.

[Setting up Hadoop with Docker and using MapReduce framework][3]

## Author
This project was implemented by [Lucas de Queiroz dos Reis][2]. It is based on the [100 Days System Design for DevOps and Cloud Engineers][1].

[1]: https://deoshankar.medium.com/100-days-system-design-for-devops-and-cloud-engineers-18af7a80bc6f "Medium - Deo Shankar 100 Days"
[2]: https://www.linkedin.com/in/lucas-de-queiroz/ "LinkedIn - Lucas de Queiroz"
[3]: https://medium.com/@guillermovc/setting-up-hadoop-with-docker-and-using-mapreduce-framework-c1cd125d4f7b "Medium - Guillermo Velazques"